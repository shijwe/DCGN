{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparative methods\n",
    "In order to prove the effectiveness of the DCGN method, the following approaches are chosen as comparison methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly,load the data and then ensure that the shape of the data is same as the shape of the tag. Then feature normalization is performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest (RF): a classifier that contains multiple decision trees and whose outputs are determined by the plurality of the classes output by individual trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n",
    "epoch = 10\n",
    "for x in range(epoch):\n",
    "    Xtrain, Xval, Ytrain, Yval = train_test_split(da1,tag,test_size=0.2)\n",
    "        \n",
    "    rfc = RandomForestClassifier(random_state=0)\n",
    "    rfc = rfc.fit(Xtrain,Ytrain)\n",
    "    pre_rfc = rfc.predict(Xval)\n",
    "    acc_rfc = accuracy_score(pre_rfc,Yval)\n",
    "    f1_rfc = f1_score(Yval, pre_rfc, average='weighted' )\n",
    "    p_rfc = precision_score(Yval,pre_rfc, average='weighted')\n",
    "    r_rfc = recall_score(Yval,pre_rfc, average='weighted')\n",
    "    kappa = cohen_kappa_score(Yval,pre_rfc)\n",
    "    ham_distance = hamming_loss(Yval,pre_rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM): the basic model is a linear classifier with the largest interval defined on the feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "random_state = np.random.RandomState(0)\n",
    "data = np.array(data)\n",
    "tag = np.array(tag)\n",
    "epoch = 10\n",
    "for t in range(epoch):\n",
    "    Xtrain, Xval, Ytrain, Yval = train_test_split(data,tag,test_size=0.2)\n",
    "    model = OneVsRestClassifier(svm.SVC(kernel='linear',probability=True,random_state=random_state))\n",
    "    clt = model.fit(Xtrain,Ytrain)\n",
    "    y_test_pred = clt.predict(Xval)\n",
    "    acc = accuracy_score(y_test_pred,Yval)\n",
    "    f1 = f1_score(Yval, y_test_pred, average='weighted' )\n",
    "    p = precision_score(Yval,y_test_pred, average='weighted')\n",
    "    r = recall_score(Yval,y_test_pred, average='weighted')\n",
    "    cm = confusion_matrix(Yval,y_test_pred)\n",
    "    kappa = cohen_kappa_score(Yval,y_test_pred)\n",
    "    ham_distance = hamming_loss(Yval,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  GBDT (Gradient Boost Decision Tree):GBDT means the decision tree  trained with the strategy of Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix\n",
    "\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    Xtrain, Xval, Ytrain, Yval = train_test_split(data,tag,test_size=0.2)\n",
    "\n",
    "    gbm= GradientBoostingClassifier(learning_rate=0.1, n_estimators=230,max_depth=3,min_samples_leaf =5, min_samples_split =5, max_features='sqrt',subsample=0.8, random_state=10)\n",
    "    gbm.fit(Xtrain,Ytrain)\n",
    "    y_pred= gbm.predict(Xval)\n",
    "    acc = accuracy_score(Yval,y_pred)\n",
    "    f1 = f1_score(Yval,y_pred, average='weighted' )\n",
    "    p = precision_score(Yval,y_pred, average='weighted')\n",
    "    r = recall_score(Yval,y_pred, average='weighted')\n",
    "    cm = confusion_matrix(Yval,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Forest: deep forest model is a deep neural network principle applied to the traditional machine learning algorithm \"random forest\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepforest import CascadeForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score,confusion_matrix\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "epoch = 10\n",
    "for i in range(epoch):\n",
    "    Xtrain, Xval, Ytrain, Yval = train_test_split(da1,tag,test_size=0.2)\n",
    "    model = CascadeForestClassifier(random_state=0)\n",
    "    model.fit(Xtrain, Ytrain)\n",
    "    y_pred = model.predict(Xval)\n",
    "    acc = accuracy_score(y_pred,Yval)\n",
    "    f1 = f1_score(Yval, y_pred, average='weighted' )\n",
    "    p = precision_score(Yval,y_pred, average='weighted')\n",
    "    r = recall_score(Yval,y_pred, average='weighted')\n",
    "    #cm = confusion_matrix(Yval,y_pred)\n",
    "    kappa = cohen_kappa_score(Yval,y_pred)\n",
    "    ham_distance = hamming_loss(Yval,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAE: it is a deep neural network model composed of multiple layers of Spase AutoEncoder (sparse self-encoder)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SAE loss function part also includes reconstruction loss, which is different from the general classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras import Input\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation,Dropout,Flatten,Dense\n",
    "from tensorflow.keras import Model,datasets\n",
    "import os\n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        super (MyModel,self).__init__()\n",
    "        #self.f5 = tf.keras.layers.Flatten()\n",
    "        self.f1 = tf.keras.layers.Dense(1024,activation ='relu')\n",
    "        self.f2= tf.keras.layers.Dense(256,activation ='relu')\n",
    "        self.f3 = tf.keras.layers.Dense(64,activation ='relu')\n",
    "        self.f4= tf.keras.layers.Dense(10)\n",
    "        self.f5 = tf.keras.layers.Dense(64,activation ='relu')\n",
    "        self.f6 = tf.keras.layers.Dense(256,activation ='relu')\n",
    "        self.f7 = tf.keras.layers.Dense(1024,activation ='relu')\n",
    "        self.f8 = tf.keras.layers.Dense(20000,activation ='relu')\n",
    "    def call(self,x):\n",
    "        x = self.f1(x)\n",
    "        x = self.f2(x)\n",
    "        x = self.f3(x)\n",
    "        x1 = self.f4(x)\n",
    "        x = self.f5(x1)\n",
    "        x = self.f6(x)\n",
    "        x = self.f7(x)\n",
    "        y = self.f8(x)\n",
    "        z = tf.concat([y,x1],axis=1)\n",
    "        return z\n",
    "    \n",
    "    \n",
    "model = MyModel()\n",
    "model.build(input_shape=(909,20000))\n",
    "model.call(Input(shape=(20000,)))\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
